{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    \"\"\"\n",
    "    Base object for all inputs and outputs.\n",
    "    \"\"\"\n",
    "    def __init__(self, value, grad):\n",
    "        self.value = value\n",
    "        self.gradient = grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SigmoidNode(object):\n",
    "    \"\"\"\n",
    "    Adds a sigmoid non-linearity to a single input\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        self.output = Node(1/(1 + np.exp(-1 * self.x.value)), 0.0)\n",
    "        return self.output\n",
    "        \n",
    "    def backward(self):\n",
    "        s = 1/(1 + np.exp(-1 * self.x.value))\n",
    "        self.x.gradient = (s * (1 - s)) * self.output.gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiplyNode(object):\n",
    "    \"\"\"\n",
    "    Multiplies two inputs\n",
    "    \"\"\"\n",
    "    def forward(self, x1, x2):\n",
    "        self.x1 = x1\n",
    "        self.x2 = x2\n",
    "        self.output = Node(self.x1.value * self.x2.value, 0)\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self):\n",
    "        self.x1.gradient = self.x2.value * self.output.gradient\n",
    "        self.x2.gradient = self.x1.value * self.output.gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddNode(object):    \n",
    "    \"\"\"\n",
    "    Adds two inputs x1 and x2.\n",
    "    \"\"\"\n",
    "    def forward(self, x1, x2):\n",
    "        self.x1 = x1\n",
    "        self.x2 = x2\n",
    "        self.output = Node(self.x1.value + self.x2.value, 0)\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self):\n",
    "        self.x1.gradient = 1 * self.output.gradient\n",
    "        self.x2.gradient = 1 * self.output.gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_neural_Net():\n",
    "    # w1 * x1\n",
    "    w1x1 = w1_mul_x1.forward(w1, x1)\n",
    "    # w2 * x2\n",
    "    w2x2 = w2_mul_x2.forward(w2, x2)\n",
    "    # w1*x1 + w2*x2\n",
    "    w1x1_w2x2 = w1x1_add_w2x2.forward(w1x1, w2x2)\n",
    "    # w1*x1 + w2*x2 + b\n",
    "    w1x1_w2x2_b = w1x1w2x2_add_b.forward(w1x1_w2x2, b)\n",
    "    # sigmoid(w1*x1 + w2*x2 + b)\n",
    "    output_1 = sigmoid_out.forward(w1x1_w2x2_b)\n",
    "    \n",
    "    output1w3 = w3_mul_output1.forward(w3,output_1)\n",
    "    \n",
    "    output1w4 = w4_mul_output1.forward(w4,output_1)\n",
    "    \n",
    "    #w3*op1 + w4*op1\n",
    "    #since the output is same the modified weight for the layer becomes\n",
    "    # (w3+w4) * op1\n",
    "    w3output1_w4output1 = w3output1_add_w4output1.forward(output1w3,output1w4)\n",
    "    w3output1_w4output1_b1 = w3output1w4output1_add_b.forward(w3output1_w4output1, b1)\n",
    "    \n",
    "    output = sigmoid_out1.forward(w3output1_w4output1_b1)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_neural_net():\n",
    "    sigmoid_out1.backward()\n",
    "    w3output1w4output1_add_b.backward()\n",
    "    w3output1_add_w4output1.backward()\n",
    "    w4_mul_output1.backward()\n",
    "    w3_mul_output1.backward()\n",
    "    \n",
    "    sigmoid_out.backward()\n",
    "    w1x1w2x2_add_b.backward()\n",
    "    w1x1_add_w2x2.backward()\n",
    "    w2_mul_x2.backward()\n",
    "    w1_mul_x1.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = Node(0.1, 0.0)\n",
    "w2 = Node(0.4, 0.0)\n",
    "w3 = Node(0.2, 0.0)\n",
    "w4 = Node(0.3, 0.0)\n",
    "b = Node(-0.02, 0.0)\n",
    "b1 = Node(-0.01, 0.0)\n",
    "\n",
    "alpha = 0.001\n",
    "x1 = Node(0.3, 0.0)\n",
    "x2 = Node(1.0, 0.0)\n",
    "y = 0.475\n",
    "\n",
    "w1_mul_x1 = MultiplyNode()\n",
    "w2_mul_x2 = MultiplyNode()\n",
    "w1x1_add_w2x2 = AddNode()\n",
    "w1x1w2x2_add_b = AddNode()\n",
    "sigmoid_out = SigmoidNode()\n",
    "\n",
    "w3_mul_output1 = MultiplyNode()\n",
    "w4_mul_output1 = MultiplyNode()\n",
    "w3output1_add_w4output1 = AddNode()\n",
    "w3output1w4output1_add_b = AddNode()\n",
    "sigmoid_out1 = SigmoidNode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5721292930904393\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4750000000518414"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_output = forward_neural_Net()\n",
    "print forward_output.value\n",
    "for i in range(100000):\n",
    "    forward_output = forward_neural_Net()\n",
    "    forward_output.gradient = -2 * (y - forward_output.value)\n",
    "    backward_neural_net()\n",
    "    w1.value -= alpha * w1.gradient\n",
    "    w2.value -= alpha * w2.gradient\n",
    "    w3.value -= alpha * w3.gradient\n",
    "    w4.value -= alpha * w4.gradient\n",
    "    b.value -= alpha * b.gradient\n",
    "    b1.value -= alpha * b1.gradient\n",
    "    \n",
    "forward_output.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a preceptron class with added method to compute the value of a node at any given instance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(object):\n",
    "    def __init__(self, x1, x2, alpha=0.001):\n",
    "        ### Hyper parameters\n",
    "        self.alpha = alpha\n",
    "        ### Initializing weights/bias to a random float between -1 and 1.\n",
    "        self.w1 = Node(np.random.uniform(-1, 1), 0.0)\n",
    "        self.w2 = Node(np.random.uniform(-1, 1), 0.0)\n",
    "        self.b = Node(np.random.uniform(-1, 1), 0.0)\n",
    "        ### Input and Output variables\n",
    "        self.x1 = Node(x1, 0.0)\n",
    "        self.x2 = Node(x2, 0.0)\n",
    "        ### Initialize operators nodes required \n",
    "        ### for processing the inputs within a perceptron\n",
    "        self.initialize_operators()\n",
    "    \n",
    "    def initialize_operators(self):\n",
    "        self.w1_mul_x1 = MultiplyNode()\n",
    "        self.w2_mul_x2 = MultiplyNode()\n",
    "        self.w1x1_add_w2x2 = AddNode()\n",
    "        self.w1x1_w2x2_add_b = AddNode()\n",
    "        self.sigmoid = SigmoidNode()\n",
    "    \n",
    "    def forward(self):\n",
    "        w1x1 = self.w1_mul_x1.forward(self.w1, self.x1)\n",
    "        w2x2 = self.w2_mul_x2.forward(self.w2, self.x2)\n",
    "        w1x1_w2x2 = self.w1x1_add_w2x2.forward(w1x1, w2x2)\n",
    "        w1x1_w2x2_b = self.w1x1_w2x2_add_b.forward(w1x1_w2x2, self.b)\n",
    "        self.sigmoid.forward(w1x1_w2x2_b)\n",
    "        \n",
    "    def backward(self):\n",
    "        self.sigmoid.backward()\n",
    "        self.w1x1_w2x2_add_b.backward()\n",
    "        self.w1x1_add_w2x2.backward()\n",
    "        self.w2_mul_x2.backward()\n",
    "        self.w1_mul_x1.backward()\n",
    "    \n",
    "    def update(self):\n",
    "        self.w1.value -= self.alpha * self.w1.gradient\n",
    "        self.w2.value -= self.alpha * self.w2.gradient\n",
    "        self.b.value -= self.alpha * self.b.gradient\n",
    "    \n",
    "    def getValue(self):\n",
    "        w1x1 = self.w1_mul_x1.forward(self.w1, self.x1)\n",
    "        w2x2 = self.w2_mul_x2.forward(self.w2, self.x2)\n",
    "        w1x1_w2x2 = self.w1x1_add_w2x2.forward(w1x1, w2x2)\n",
    "        w1x1_w2x2_b = self.w1x1_w2x2_add_b.forward(w1x1_w2x2, self.b)\n",
    "        return self.sigmoid.forward(w1x1_w2x2_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second perceptron is initialized with the outputs of the 1st perceptron and after initialization the whole network is trained to optimize the values of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7893539772555763\n",
      "0.3481972639817004\n",
      "0.3481972639817004\n",
      "0.3481972639817001\n"
     ]
    }
   ],
   "source": [
    "p = Perceptron(0.11, -1.0, alpha=0.1)\n",
    "\n",
    "print p.getValue().value\n",
    "p1 = Perceptron(p.getValue().value,p.getValue().value,alpha=0.01)\n",
    "\n",
    "# number of iterations\n",
    "N = 100000\n",
    "# expected output \n",
    "target = 0.3481972639817\n",
    "\n",
    "for i in range(N):\n",
    "    # Step 1. Forward Pass\n",
    "    p.forward()\n",
    "    p1.forward()\n",
    "    # Step 2. Calculate Loss. -2 * (y - output) is the gradient of output w.r.t \n",
    "    # square loss function.\n",
    "    p1.sigmoid.output.gradient = -2 * (target - p1.sigmoid.output.value)\n",
    "    p1.backward()\n",
    "    p1.update()\n",
    "    \n",
    "    p.sigmoid.output.gradient = -2 * (target - p.sigmoid.output.value)\n",
    "    # Step 3. Backward Pass\n",
    "    p.backward()\n",
    "    # Step 4. Update Weights and Bias\n",
    "    p.update()\n",
    "    \n",
    "#     if N%500 == 0:\n",
    "#         print \"p : \",p.getValue().value\n",
    "#         print \"p1 : \", p1.getValue().value\n",
    "\n",
    "print p1.getValue().value\n",
    "print p.getValue().value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Node object at 0x7f67e4379150>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
